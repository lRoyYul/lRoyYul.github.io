---
title: "Leyi Yu Blog"
format: html
---

# Study 1

```{r}
library(readr) 
library(dplyr)
library(lubridate)
library(ggplot2)
library(tidyr)
library(purrr)
library(jsonlite)
```

This chunk loads the TMDB 5000 movie dataset and constructs two key variables for downstream analyses. First, release_decade translates each film’s release_date into a decade factor (1980s through 2020s), which we use as a multi-level grouping variable. Second, english_group classifies films based on original_language, with “English” assigned when the lower-cased code equals "en" and “Non-English” otherwise. These transformations align the raw data with the Study 1 requirements by creating one binary factor for two-group comparisons and one categorical factor for 3–6 group comparisons.

```{r}
df <- read_csv("data/tmdb_5000_movies.csv", show_col_types = FALSE)
df <- df |>
  mutate(
    release_date_parsed = suppressWarnings(ymd(release_date)),
    release_decade = case_when(
      year(release_date_parsed) >= 1980 & year(release_date_parsed) < 1990 ~ "1980s",
      year(release_date_parsed) >= 1990 & year(release_date_parsed) < 2000 ~ "1990s",
      year(release_date_parsed) >= 2000 & year(release_date_parsed) < 2010 ~ "2000s",
      year(release_date_parsed) >= 2010 & year(release_date_parsed) < 2020 ~ "2010s",
      year(release_date_parsed) >= 2020 & year(release_date_parsed) < 2030 ~ "2020s",
      TRUE ~ NA_character_
      ),
     english_group = ifelse(
      !is.na(original_language) & tolower(original_language) == "en",
      "English", "Non-English"
      )
  ) 

df_filter <- df |>
  filter(
    !is.na(release_date_parsed),
    !is.na(genres), genres != "", genres != "[]",
    !is.na(revenue), revenue >= 0,
    !is.na(budget),  budget  >= 0,
    !is.na(vote_average), vote_average >= 0, vote_average <= 10
  )
```

This chunk narrows the data to analytically usable observations. We retain only rows with a parsable release date, nonempty genres, and nonnegative revenue and budget. We also restrict vote_average to the valid \[0, 10\] range. This filtering step improves internal validity by removing records that would otherwise contribute noise or impossible values, while preserving the sample size needed for the required hypothesis tests and graphics.

## Task b

```{r}
b_ttest <- t.test(
  vote_average ~ english_group,
  data = df_filter,
  conf.level = 0.90
)
b_ttest
df_filter |>
  group_by(english_group) |>
  summarize(
    n   = n(),
    mean = mean(vote_average),
    sd   = sd(vote_average),
    .groups = "drop"
  )

df_filter |>
  ggplot(aes(vote_average, fill = english_group)) +
  geom_density(alpha = 0.35) +
  labs(x = "Vote Average", y = "Density", fill = "Group")
```

This chunk compares mean user ratings between English and Non-English films using a Welch two-sample t-test with a 90% confidence interval. In the filtered data, the English group contains 4,477 films with an average rating of about 6.09 (sd ≈ 1.13), whereas the Non-English group contains 298 films with an average rating of about 6.49 (sd ≈ 1.27). The test statistic is approximately −5.37 with roughly 329 degrees of freedom, yielding a p-value on the order of 10⁻⁷. The 90% confidence interval for the mean difference (English minus Non-English) is roughly \[−0.53, −0.28\], which excludes zero. Taken together with the density plot—which shows the Non-English distribution shifted to the right—these results indicate that Non-English films receive modestly but credibly higher average ratings than English-language films, and the magnitude of the difference is on the order of four-tenths of a rating point on a 0–10 scale.

## Task c

```{r}
df_c <- df_filter |>
  mutate(log_revenue = log1p(revenue)) |>
  filter(!is.na(release_decade)) |>
  group_by(release_decade) |>
  mutate(n_decade = n()) |>
  ungroup() 

df_c |>
  ggplot(aes(x = release_decade, y = log_revenue)) +
  geom_boxplot() +
  labs(x = "Release decade", y = "log(Revenue + 1)",
       title = "Distribution of log(Revenue+1) by decade")

df_c |>
  count(release_decade, sort = TRUE)

fit_c <- aov(log_revenue ~ release_decade, data = df_c)
summary(fit_c)

TukeyHSD(fit_c, conf.level = 0.90)

tbl_c <- df_c |>
  group_by(release_decade) |>
  summarize(
    n    = n(),
    mean = mean(log_revenue),
    sd   = sd(log_revenue),
    .groups = "drop"
  )
tbl_c
```

This block examines decade differences in revenue on a log scale. The boxplot of log(Revenue + 1) by release_decade suggests modest shifts across decades, and the one-way ANOVA formalizes that pattern by testing equality of decade means. Tukey’s 90% confidence intervals then identify which specific decade pairs differ; interpret any pair whose interval excludes zero as a credible difference at the assignment’s 90% level, and read the sign of the contrast to determine which decade has the higher mean.

## Task d

```{r}
df_d <- df_filter |>
  filter(!is.na(english_group)) |>
  mutate(profit = as.integer(revenue >2.4* budget)) |>
  select(english_group, profit)

tab_wide <- df_d |>
  mutate(english_group = factor(english_group, levels = c("English","Non-English"))) |>
  count(english_group, profit) |>
  pivot_wider(names_from = profit, values_from = n, values_fill = 0) |>
  rename(not_profit = `0`, profit = `1`) |>
  arrange(english_group)

tab_wide 

a <- tab_wide |> filter(english_group == "English")     |> pull(profit)
b <- tab_wide |> filter(english_group == "English")     |> pull(not_profit)
c <- tab_wide |> filter(english_group == "Non-English") |> pull(profit)
d <- tab_wide |> filter(english_group == "Non-English") |> pull(not_profit)


c(a=a, b=b, c=c, d=d)


p1 <- a/(a+b)  
p2 <- c/(c+d)   

rd_test <- prop.test(x = c(a,c), n = c(a+b, c+d), conf.level = 0.90, correct = TRUE)
rd_est  <- unname(p1 - p2)
rd_ci   <- unname(rd_test$conf.int)

RR <- p1/p2
se_logRR <- sqrt(1/a - 1/(a+b) + 1/c - 1/(c+d))
z <- qnorm(0.95)  
RR_ci <- exp(log(RR) + c(-1,1)*z*se_logRR)

or_test <- fisher.test(matrix(c(a,b,c,d), nrow = 2), conf.level = 0.90)
OR <- unname(or_test$estimate)
OR_ci <- unname(or_test$conf.int)

tibble::tibble(
  metric   = c("Risk_English (p1)", "Risk_NonEnglish (p2)", "RD = p1 - p2", "RR = p1/p2", "OR"),
  estimate = c(p1, p2, rd_est, RR, OR),
  ci90_lwr = c(NA, NA, rd_ci[1], RR_ci[1], OR_ci[1]),
  ci90_upr = c(NA, NA, rd_ci[2], RR_ci[2], OR_ci[2])
)

df_d |>
  mutate(profit = factor(profit, levels = c(0,1), labels = c("Not profit","Profit"))) |>
  count(english_group, profit) |>
  group_by(english_group) |>
  mutate(pct = n / sum(n)) |>
  ungroup() |>
  ggplot(aes(x = english_group, y = pct, fill = profit)) +
  geom_col(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(x = "Group", y = "Share", fill = "", 
       title = "Profit vs Not profit proportion by group")

```

This block evaluates whether profitability differs by language using a 2×2 table with profit = I(revenue \> budget) as the outcome and english_group as the exposure. We report three effect measures with 90% confidence intervals—risk difference (RD), relative risk (RR), and odds ratio (OR). A 90% CI for RD that excludes zero (and RR/OR intervals that exceed one) indicates English-language films have a credibly higher probability of being profitable; if the intervals include the null values, the data do not provide sufficient evidence of a difference at the 90% level.

## Task e

```{r}
top_k <- 5

safe_parse_genres <- function(s) {
  if (is.na(s) || s == "" || s == "[]") return(list())
  out <- tryCatch(jsonlite::fromJSON(s), error = function(e) NULL)
  if (is.null(out)) return(list())
  if (is.data.frame(out) && "name" %in% names(out)) {
    as.character(out$name)
  } else if (is.list(out)) {
    unlist(lapply(out, function(x) tryCatch(as.character(x$name), error = function(e) NA_character_)), use.names = FALSE)
  } else character()
}

df_gen_long <- df_filter |>
  filter(!is.na(release_decade)) |>
  mutate(genres_vec = purrr::map(genres, safe_parse_genres)) |>
  tidyr::unnest_longer(genres_vec, values_to = "genre") |>
  filter(!is.na(genre), genre != "")

top_genres <- df_gen_long |>
  count(genre, sort = TRUE) |>
  slice_head(n = top_k) |>
  pull(genre)

heat_rev_mean <- df_gen_long |>
  filter(genre %in% top_genres) |>
  mutate(
    release_decade = factor(release_decade, levels = c("1980s","1990s","2000s","2010s","2020s")),
    log_revenue = log1p(revenue)
  ) |>
  group_by(release_decade, genre) |>
  summarize(mean_log_rev = mean(log_revenue), .groups = "drop")

heat_rev_mean |>
  ggplot(aes(x = release_decade, y = genre, fill = mean_log_rev)) +
  geom_tile() +
  labs(x = "Decade", y = "Genre (TopK)",
       fill = "Mean log(Rev+1)",
       title = "Mean log(Revenue+1) by decade × genre")

xtab_counts <- df_gen_long |>
  filter(genre %in% top_genres) |>
  count(release_decade, genre) |>
  tidyr::pivot_wider(names_from = genre, values_from = n, values_fill = 0) |>
  arrange(factor(release_decade, levels = c("1980s","1990s","2000s","2010s","2020s")))

xtab_counts  

xtab_rowprop <- xtab_counts |>
  tibble::column_to_rownames("release_decade") |>
  as.matrix() |>
  prop.table(margin = 1) |>
  as.data.frame() |>
  tibble::rownames_to_column("release_decade")

xtab_rowprop 

mat_counts <- xtab_counts |>
  tibble::column_to_rownames("release_decade") |>
  as.matrix()

chisq_res <- chisq.test(mat_counts) 
```

This chunk expands multi-label genres into a long format so each film contributes to all of its tags, selects the Top-K genres by overall frequency, and then maps color to the mean of log(Revenue + 1) within each decade–genre cell. Darker tiles indicate decade–genre combinations associated with higher average revenues on the log scale. The follow-up cross-tabulation reports counts by decade and genre together with row-wise proportions, which show how the composition of popular genres shifts over time (for example, Drama typically occupies the largest share and Comedy the second largest, while smaller genres fluctuate in relative weight). A Pearson chi-square test applied to the count table assesses whether decade and genre are independent; the test rejects independence at conventional levels, implying that the distribution of genres changes across decades. Because the heatmap summarizes average log revenue rather than counts, and because each film contributes to all of its genres, these EDA results should be interpreted descriptively: they highlight where revenue tends to be stronger without implying mutually exclusive group membership or causal effects.
